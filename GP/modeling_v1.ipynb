{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20 trials: X1, X2, ..., X20\n",
    "keep the depth as 9\n",
    "\n",
    "Each trial has sequence of points: X1 = {x11, x12, x13, ..., x15}\n",
    "\n",
    "Algorithm:\n",
    "    1. upload X1 with given depth for 9 different objects\n",
    "    2. optimize hyperparameters for all of the models\n",
    "    3. predict depth+1, record probability, get label\n",
    "    4. re-upload X1 with new, remove anything far before depth+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.linalg import cholesky, cho_solve, solve_triangular\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data[obj_name][trial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../dataset.pkl', 'rb'))\n",
    "df = pd.read_csv('../df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thumb_1</th>\n",
       "      <th>thumb_2</th>\n",
       "      <th>thumb_3</th>\n",
       "      <th>thumb_4</th>\n",
       "      <th>thumb_5</th>\n",
       "      <th>thumb_6</th>\n",
       "      <th>thumb_7</th>\n",
       "      <th>thumb_8</th>\n",
       "      <th>thumb_9</th>\n",
       "      <th>thumb_10</th>\n",
       "      <th>...</th>\n",
       "      <th>little_5</th>\n",
       "      <th>little_6</th>\n",
       "      <th>little_7</th>\n",
       "      <th>little_8</th>\n",
       "      <th>little_9</th>\n",
       "      <th>little_10</th>\n",
       "      <th>little_11</th>\n",
       "      <th>little_12</th>\n",
       "      <th>obj_name</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05098</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>blue_bear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05098</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>blue_bear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05098</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>blue_bear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05098</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>blue_bear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05098</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>blue_bear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   thumb_1   thumb_2   thumb_3   thumb_4   thumb_5   thumb_6   thumb_7  \\\n",
       "0  0.05098  0.050980  0.054902  0.047059  0.047059  0.047059  0.050980   \n",
       "1  0.05098  0.050980  0.054902  0.047059  0.047059  0.050980  0.050980   \n",
       "2  0.05098  0.054902  0.054902  0.050980  0.050980  0.047059  0.047059   \n",
       "3  0.05098  0.054902  0.054902  0.047059  0.050980  0.050980  0.050980   \n",
       "4  0.05098  0.054902  0.054902  0.050980  0.050980  0.050980  0.047059   \n",
       "\n",
       "    thumb_8   thumb_9  thumb_10  ...    little_5  little_6  little_7  \\\n",
       "0  0.047059  0.047059  0.050980  ...    0.027451  0.031373  0.027451   \n",
       "1  0.050980  0.047059  0.047059  ...    0.031373  0.027451  0.027451   \n",
       "2  0.050980  0.047059  0.050980  ...    0.027451  0.031373  0.027451   \n",
       "3  0.050980  0.047059  0.050980  ...    0.035294  0.031373  0.027451   \n",
       "4  0.050980  0.047059  0.047059  ...    0.035294  0.031373  0.027451   \n",
       "\n",
       "   little_8  little_9  little_10  little_11  little_12   obj_name  trial  \n",
       "0  0.031373  0.035294   0.031373   0.027451   0.039216  blue_bear      1  \n",
       "1  0.027451  0.039216   0.027451   0.031373   0.043137  blue_bear      1  \n",
       "2  0.027451  0.031373   0.035294   0.027451   0.039216  blue_bear      1  \n",
       "3  0.031373  0.031373   0.035294   0.027451   0.043137  blue_bear      1  \n",
       "4  0.027451  0.035294   0.027451   0.031373   0.039216  blue_bear      1  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_names = list(df['obj_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_to_id = {\n",
    "    'blue_bear':1,\n",
    "    'med_coke':2,\n",
    "    'book':3,\n",
    "    'empty_coke':4,\n",
    "    'lotion':5,\n",
    "    'empty_vitamin_water':6,\n",
    "    'med_vitamin_water':7,\n",
    "    'full_vitamin_water':8,\n",
    "    'monkey_toy':9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blue_bear',\n",
       " 'med_coke',\n",
       " 'book',\n",
       " 'empty_coke',\n",
       " 'lotion',\n",
       " 'empty_vitamin_water',\n",
       " 'med_vitamin_water',\n",
       " 'full_vitamin_water',\n",
       " 'monkey_toy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_exp_kernel(X, theta_):\n",
    "    pairwise_dists = squareform(pdist(X, 'euclidean'))**2\n",
    "    K = np.exp(-pairwise_dists/ (2 * theta_[0] ** 2))\n",
    "    K_gradient = np.multiply(pairwise_dists/(theta_[0]**3), K)\n",
    "    return K, np.expand_dims(K_gradient, axis=2)\n",
    "\n",
    "def squared_exp_kernel_func(a, b, theta_):\n",
    "    # theta includes number of parameters\n",
    "    squared_dist = np.linalg.norm(a-b)**2\n",
    "    k = np.exp(-squared_dist/(2*theta_[0]**2))\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZATION_ITERATIONS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP:\n",
    "    def __init__(self, sigma_n_square, bounds):\n",
    "        self.sigma_n_square = sigma_n_square\n",
    "        self.bounds = bounds\n",
    "    \n",
    "    def set_data(self, X_, y_):\n",
    "        self.X = X_.copy()\n",
    "        self.y = y_.copy()\n",
    "        \n",
    "        \n",
    "    def log_marginal_likelihood(self, theta_, *args):    \n",
    "        #K, K_gradient = squared_exp_kernel(X, theta_=theta_)\n",
    "        K, K_gradient = squared_exp_kernel(self.X, theta_=theta_)\n",
    "\n",
    "\n",
    "        # do Cholesky decomposition\n",
    "        L = cholesky(K + self.sigma_n_square*np.eye(len(self.X)), lower=True)\n",
    "        #print(L)\n",
    "        # solve for alpha\n",
    "        alpha = cho_solve(  (L, True), self.y )\n",
    "        #print(K_gradient.shape)\n",
    "\n",
    "        tmp = np.einsum(\"ik,jk->ijk\", alpha, alpha)  # k: output-dimension\n",
    "        tmp -= cho_solve((L, True), np.eye(K.shape[0]))[:, :, np.newaxis]\n",
    "        log_likelihood_gradient_dims = 0.5 * np.einsum(\"ijl,ijk->kl\", tmp, K_gradient)\n",
    "        log_likelihood_gradient = log_likelihood_gradient_dims.sum(-1)\n",
    "\n",
    "        return -( -0.5*np.dot(self.y.T, alpha) - np.sum(np.log(L.diagonal())) - self.X.shape[0]/2*np.log(2*np.pi) ), -log_likelihood_gradient\n",
    "\n",
    "        #log_likelihood_gradients = []\n",
    "        #for dim in range(X.shape[1]):\n",
    "        #    log_likelihood_gradient_dims = 0.5 * np.einsum(\"ijl,ijk->kl\", tmp, K_gradient[dim])\n",
    "        #    log_likelihood_gradient = log_likelihood_gradient_dims.sum(-1)\n",
    "        #    log_likelihood_gradients.append(-log_likelihood_gradient)\n",
    "\n",
    "        #return -( -0.5*np.dot(y.T, alpha) - np.sum(np.log(L.diagonal())) - X.shape[0]/2*np.log(2*np.pi) ), np.array(log_likelihood_gradients)\n",
    "        \n",
    "    def optimize_kernel_parameters(self, x0):\n",
    "        theta_estimate, min_log_marginal_likelihood, info = fmin_l_bfgs_b(func=self.log_marginal_likelihood, x0=x0, args=(), bounds=bounds)\n",
    "        # print('Optimization succeded with log marginal likelihood ', min_log_marginal_likelihood[0][0], ' in ', info['funcalls'],' iterations.')\n",
    "        return  theta_estimate, min_log_marginal_likelihood, info\n",
    "    \n",
    "    def optimize_kernels(self, x0):\n",
    "        log_likelihood_list = []\n",
    "        theta_est_list  = []\n",
    "        for i in range(OPTIMIZATION_ITERATIONS):\n",
    "            #bounds = np.array(bounds)\n",
    "            theta_initial = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1])\n",
    "            theta_estimate, min_log_marginal_likelihood, info = self.optimize_kernel_parameters(x0)\n",
    "            log_likelihood_list.append(min_log_marginal_likelihood[0][0])\n",
    "            theta_est_list.append(theta_estimate)\n",
    "        return theta_estimate[np.argmin(log_likelihood_list)]\n",
    "    \n",
    "        # make prediction\n",
    "    def predict(self, x_star, theta_):\n",
    "\n",
    "        # create covariance matrix using kernel\n",
    "        #K = pairwise_kernels(X, metric=kernel_func,  theta_=theta)\n",
    "        K, _ = squared_exp_kernel(self.X, theta_=theta_)\n",
    "        #print(K)\n",
    "\n",
    "        # do Cholesky decomposition\n",
    "        L = cholesky(K + self.sigma_n_square*np.eye(self.X.shape[0]), lower=True)\n",
    "\n",
    "        # solve for alpha\n",
    "        alpha = cho_solve(    (L, True),    self.y   )\n",
    "\n",
    "        L_inv = solve_triangular(L.T, np.eye(L.shape[0]))\n",
    "        K_inv = L_inv.dot(L_inv.T)\n",
    "\n",
    "        k_star = pairwise_kernels(x_star, self.X, metric=squared_exp_kernel_func,  theta_= theta_)\n",
    "        y_mean = k_star.dot(alpha) + np.mean(self.y)\n",
    "        y_var = np.ones(x_star.shape[0]) - np.einsum(\"ij,ij->i\", np.dot(k_star, K_inv), k_star)\n",
    "        y_var[y_var < 0] = 0\n",
    "\n",
    "        # log marginal likelihood\n",
    "        # log_marg_likelihood = -0.5*np.dot(self.y.T, alpha) - np.sum(np.log(L.diagonal())) - self.X.shape[0]/2*np.log(2*np.pi)\n",
    "\n",
    "        #print(-0.5*np.dot(y.T, alpha) - np.sum(np.log(L.diagonal())) - X.shape[0]/2*np.log(2*np.pi))\n",
    "        return y_mean, np.sqrt(y_var) #, log_marg_likelihood\n",
    "    \n",
    "    def pdf(self, x_, mu_, sigma_):\n",
    "        if sigma_[0] == 0:\n",
    "            return  np.array([[0]])\n",
    "        return  np.exp( - (x_ - mu_)**2 / (2 * sigma_**2) )* 1/ ( np.sqrt(2*np.pi) * sigma_)\n",
    "    \n",
    "    def predict_all(self, x_new, models_):\n",
    "        list_of_pred = []\n",
    "        #list_of_sigma = []\n",
    "        for obj in models_:\n",
    "            #print(obj,  models_[obj])\n",
    "            y_pred, y_sigma = self.predict(theta_= models_[obj], x_star=X_temp)\n",
    "            prob  = self.pdf(x_= y_pred, mu_= 1, sigma_=y_sigma)\n",
    "            list_of_pred.append(prob[0])\n",
    "        print(list_of_pred)\n",
    "            #list_of_sigma.append(prob[0])\n",
    "        return np.argmax(np.array(list_of_pred)) + 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def optimize_kernels(x0)\n",
    "    log_likelihood_list = []\n",
    "    theta_est_list  = []\n",
    "    for i in range(OPTIMIZATION_ITERATIONS):\n",
    "        bounds = np.array(bounds)\n",
    "        theta_initial = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        theta_estimate, min_log_marginal_likelihood, info = optimize_kernel_parameters(x0)\n",
    "        log_likelihood_list.append(min_log_marginal_likelihood[0][0])\n",
    "        theta_est_list.append(theta_estimate)\n",
    "    return theta_estimate[np.argmin(log_likelihood_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_BOUND = (1e-2,1e2)\n",
    "SIGMA_N_SQUARE = 1e-10\n",
    "DEPTH = 4\n",
    "NUMBER_OF_HYPERPARAMETERS = 1\n",
    "OPTIMIZATION_ITERATIONS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiliaze boundaries: # boundries = # type\n",
    "bounds = []\n",
    "for i in range(NUMBER_OF_HYPERPARAMETERS):\n",
    "    bounds.append(LOCAL_BOUND)\n",
    "x0 = np.ones(len(bounds))\n",
    "bounds = np.array(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize the models: assign initial theta values\n",
    "models = {}\n",
    "for obj in obj_names:\n",
    "    models[obj] = x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 60)\n",
      "blue_bear\n",
      "med_coke\n",
      "book\n",
      "empty_coke\n",
      "lotion\n",
      "empty_vitamin_water\n",
      "med_vitamin_water\n",
      "full_vitamin_water\n",
      "monkey_toy\n"
     ]
    }
   ],
   "source": [
    "my_gp = GP(sigma_n_square=SIGMA_N_SQUARE, bounds=bounds)\n",
    "\n",
    "# initilize the first training set\n",
    "trial = 1\n",
    "X = np.zeros([1,60])\n",
    "y = np.ones([1,1])\n",
    "for obj in obj_names:\n",
    "    X_temp = data[obj][trial][0:DEPTH]\n",
    "    y_temp = np.ones(X_temp.shape[0])*obj_to_id[obj]\n",
    "    y_temp = y_temp.reshape(-1,1)\n",
    "    X = np.vstack([X, X_temp])\n",
    "    y = np.vstack([y, y_temp])\n",
    "    \n",
    "X = X[1:]\n",
    "y = y[1:]\n",
    "print(X.shape)\n",
    "\n",
    "# train 9 models\n",
    "for obj in obj_names:\n",
    "    print(obj)\n",
    "    y_train = y.copy()\n",
    "    y_train[y == obj_to_id[obj]] = 1\n",
    "    y_train[y != obj_to_id[obj]] = -1\n",
    "    my_gp.set_data(X_= X, y_ = y_train)\n",
    "    #theta_estimate, _, info = my_gp.optimize_kernel_parameters(models[obj])\n",
    "    theta_estimate = my_gp.optimize_kernels(models[obj])\n",
    "    models[obj] = np.array([theta_estimate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue_bear': array([45.3350202]),\n",
       " 'med_coke': array([4.43186673]),\n",
       " 'book': array([68.34528685]),\n",
       " 'empty_coke': array([1.]),\n",
       " 'lotion': array([1.86009582]),\n",
       " 'empty_vitamin_water': array([7.375]),\n",
       " 'med_vitamin_water': array([35.4600811]),\n",
       " 'full_vitamin_water': array([40.75000005]),\n",
       " 'monkey_toy': array([1.])}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_sigma = my_gp.predict(theta_= models[obj], x_star=np.array([X[14, :]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.55556022]]), array([0.]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gp.pdf(x_= y_pred, mu_= 1, sigma_=y_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.,  0., nan, nan]), array([ 0.,  0., nan,  0.]), array([0]), array([ 0., nan, nan,  0.]), array([0]), array([0., 0., 0., 0.]), array([0]), array([0]), array([ 0., nan, nan,  0.])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tasbolat/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:85: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/tasbolat/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/tasbolat/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:52: RuntimeWarning: invalid value encountered in greater\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-b278bb32195a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-143-8641fac4a4e9>\u001b[0m in \u001b[0;36mpredict_all\u001b[0;34m(self, x_new, models_)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m#list_of_sigma.append(prob[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \"\"\"\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "y_pred = my_gp.predict_all(x_new=X[14], models_=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.03390088]), array([0.]), array([0.]), array([0]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "obj = 'med_coke'\n",
    "for i in range(DEPTH, 4):\n",
    "    X_temp = data[obj][trial][i:i+1]\n",
    "    if X_temp.shape[0] == 0:\n",
    "        break\n",
    "    #y_temp = np.array([1])*obj_to_id[obj]\n",
    "    #y_temp = y_temp.reshape(-1,1)\n",
    "    \n",
    "    # do prediction\n",
    "    #y_pred, y_sigma = my_gp.predict(theta_= models[obj], x_star=X_temp)\n",
    "    #print(y_pred, y_sigma)\n",
    "    \n",
    "    y_pred = my_gp.predict_all(x_new=X_temp, models_=models)\n",
    "    print(y_pred)\n",
    "    #X = np.vstack([X, X_temp])\n",
    "    #y = np.vstack([y, y_temp])\n",
    "    \n",
    "    #X = X[1:]\n",
    "    #y = y[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42810323])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gp.pdf(x_= y_pred, mu_= 1, sigma_=y_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue_bear': array([0.01]),\n",
       " 'med_coke': array([0.50500718]),\n",
       " 'book': array([1.04760671]),\n",
       " 'empty_coke': array([100.]),\n",
       " 'lotion': array([1.00000001]),\n",
       " 'empty_vitamin_water': array([1.]),\n",
       " 'med_vitamin_water': array([0.66248095]),\n",
       " 'full_vitamin_water': array([1.]),\n",
       " 'monkey_toy': array([1.22691006])}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-135-3391f878e900>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-135-3391f878e900>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    X =\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for trial in range(1, 21):\n",
    "    for i in range(20):\n",
    "        for obj in obj_names:\n",
    "            mask = (df.obj_name == obj) & (df.trial == trial)\n",
    "            X = \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
